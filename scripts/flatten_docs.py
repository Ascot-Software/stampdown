#!/usr/bin/env python3
import argparse
import os
import re
import sys
from typing import List, Optional, Tuple

# Match markdown links: [text](target)
MD_LINK_RE = re.compile(r'\[([^\]]+)\]\(([^)]+)\)')
# Match HTML links: <a href="target">text</a>
HTML_LINK_RE = re.compile(r'<a\s+href="([^"]*)">(.*?)</a>', re.IGNORECASE)

visited = set()
output_chunks: List[str] = []


def normalize_target(current_file: str, target: str) -> Optional[str]:
    """
    Turn a link target into a normalized relative .md path, or None if:
    - it's external (has ://),
    - it's an anchor-only link,
    - or it's not a .md file.
    """
    # strip anchor if present
    target = target.split("#", 1)[0].strip()
    if not target:
        return None

    # external link
    if "://" in target:
        return None

    # we only care about .md files
    if not target.endswith(".md"):
        return None

    current_dir = os.path.dirname(current_file)
    return os.path.normpath(os.path.join(current_dir, target))


def strip_comment_and_breadcrumbs(text: str) -> str:
    """
    Remove the 'Do not edit this file' line and breadcrumb lines like:
    [Home](./index.md) > [@pkg](./pkg.md) > [Class](./pkg.class.md)
    """
    lines = text.splitlines()
    cleaned_lines: List[str] = []

    for line in lines:
        # Drop the "Do not edit this file" line
        if "Do not edit this file" in line and "API Documenter" in line:
            continue

        # Drop breadcrumb lines (API Documenter style)
        stripped = line.strip()
        if stripped.startswith("[") and ("&gt;" in stripped or ">" in stripped):
            if MD_LINK_RE.search(stripped):
                # looks like a breadcrumb
                continue

        cleaned_lines.append(line)

    return "\n".join(cleaned_lines)


def clean_and_collect(text: str, rel_path: str) -> Tuple[str, List[str]]:
    """
    - Strip 'do not edit' and breadcrumbs
    - Collect internal .md links in the order they appear
    - Remove link markup so only visible text remains
    """
    text = strip_comment_and_breadcrumbs(text)

    children: List[str] = []
    seen_child = set()

    # Collect children from markdown links
    for m in MD_LINK_RE.finditer(text):
        href = m.group(2)
        norm = normalize_target(rel_path, href)
        if norm and norm not in seen_child:
            seen_child.add(norm)
            children.append(norm)

    # Collect children from HTML links
    for m in HTML_LINK_RE.finditer(text):
        href = m.group(1)
        norm = normalize_target(rel_path, href)
        if norm and norm not in seen_child:
            seen_child.add(norm)
            children.append(norm)

    # Strip link markup, keep only visible text
    text = MD_LINK_RE.sub(lambda m: m.group(1), text)
    text = HTML_LINK_RE.sub(lambda m: m.group(2), text)

    return text, children


def read_file(rel_path: str, root_dir: str) -> str:
    full_path = os.path.join(root_dir, rel_path)
    if not os.path.exists(full_path):
        sys.stderr.write(f"Warning: {full_path} not found, skipping\n")
        return ""
    with open(full_path, "r", encoding="utf-8") as f:
        return f.read()


def process_members(rel_path: str, root_dir: str) -> None:
    """
    Process member-level files (constructors, methods, properties, etc.).
    """
    rel_path = os.path.normpath(rel_path)
    if rel_path in visited:
        return
    visited.add(rel_path)

    text = read_file(rel_path, root_dir)
    if not text:
        return

    cleaned, child_paths = clean_and_collect(text, rel_path)

    # Delimiter between member docs
    output_chunks.append("\n\n---\n\n")
    output_chunks.append(cleaned)

    for child in child_paths:
        if child not in visited:
            process_members(child, root_dir)


def process_type(rel_path: str, root_dir: str) -> None:
    """
    Process a type-level file (Class, Interface, Enum, etc.)
    and inline its member docs.
    """
    rel_path = os.path.normpath(rel_path)
    if rel_path in visited:
        return
    visited.add(rel_path)

    text = read_file(rel_path, root_dir)
    if not text:
        return

    cleaned, child_paths = clean_and_collect(text, rel_path)

    # Delimiter between types
    output_chunks.append("\n\n---\n\n")
    output_chunks.append(cleaned)

    for child in child_paths:
        if child not in visited:
            process_members(child, root_dir)


def process_package(rel_path: str, root_dir: str) -> None:
    """
    Process a package-level file (e.g. cli.md) and then its contained types.
    """
    rel_path = os.path.normpath(rel_path)
    if rel_path in visited:
        return
    visited.add(rel_path)

    text = read_file(rel_path, root_dir)
    if not text:
        return

    cleaned, child_paths = clean_and_collect(text, rel_path)

    # Delimiter between packages
    output_chunks.append("\n\n---\n\n")
    output_chunks.append(cleaned)

    for child in child_paths:
        if child not in visited:
            process_type(child, root_dir)


def main():
    parser = argparse.ArgumentParser(
        description="Flatten @microsoft/api-documenter markdown into a single file, "
                    "grouped by package and class."
    )
    parser.add_argument(
        "docs_dir",
        help="Directory containing the generated .md files (e.g. api-docs/).",
    )
    parser.add_argument(
        "--entry",
        default="index.md",
        help="Entry markdown file to start from (default: index.md).",
    )

    args = parser.parse_args()
    docs_dir = os.path.abspath(args.docs_dir)
    entry = os.path.normpath(args.entry)

    # ðŸ”§ Mark entry as visited so we don't process it again as a package
    visited.add(entry)

    # 1. Process index.md: keep it at the very top
    index_text = read_file(entry, docs_dir)
    if not index_text:
        sys.stderr.write("Error: entry file not found or empty.\n")
        sys.exit(1)

    cleaned_index, index_children = clean_and_collect(index_text, entry)

    # Header comment for the combined file
    output_chunks.append("<!-- Combined API docs generated from @microsoft/api-documenter output -->\n")
    output_chunks.append(cleaned_index)

    # 2. Treat links from index as packages/namespaces and process each
    for pkg in index_children:
        norm_pkg = os.path.normpath(pkg)
        # ðŸ”§ Skip self-link to index.md
        if norm_pkg == entry:
            continue
        if norm_pkg not in visited:
            process_package(norm_pkg, docs_dir)

    sys.stdout.write("".join(output_chunks))


if __name__ == "__main__":
    main()
